{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes GaussianNB on training set: 0.59\n",
      "Accuracy of Naive Bayes GaussianNB on test set: 0.37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.44      0.27         9\n",
      "           2       0.33      0.16      0.21        19\n",
      "           3       0.33      0.20      0.25         5\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      1.00      1.00         6\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        43\n",
      "   macro avg       0.42      0.47      0.42        43\n",
      "weighted avg       0.40      0.37      0.36        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# load glass data set\n",
    "df = pd.read_csv('glass.csv')\n",
    "x = df[['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']]\n",
    "y = df['Type']\n",
    "\n",
    "# Use cross validation to create training and testing part\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print('Accuracy of Naive Bayes GaussianNB on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "# Evaluate the model on testing part\n",
    "print('Accuracy of Naive Bayes GaussianNB on test set: {:.2f}'.format(clf.score(X_test, y_test)))\n",
    "\n",
    "gnb = clf.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test,gnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 9) (171,)\n",
      "(43, 9) (43,)\n",
      "Accuracy of SVM classifier on training set: 0.43\n",
      "Accuracy of SVM classifier on test set: 0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.44      0.27         9\n",
      "           2       0.33      0.16      0.21        19\n",
      "           3       0.33      0.20      0.25         5\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      1.00      1.00         6\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        43\n",
      "   macro avg       0.42      0.47      0.42        43\n",
      "weighted avg       0.40      0.37      0.36        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajpadarthi/anaconda3/envs/work/lib/python3.5/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# load glass data set\n",
    "df = pd.read_csv('glass.csv')\n",
    "x = df[['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']]\n",
    "y = df['Type']\n",
    "\n",
    "# Use cross validation to create training and testing part\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Implement linear SVM method using scikit library\n",
    "svm = LinearSVC(random_state=0, tol=1e-5)\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'.format(svm.score(X_train, y_train)))\n",
    "# test data set acc\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, y_test)))\n",
    "\n",
    "svc = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test,svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 9) (171,)\n",
      "(43, 9) (43,)\n",
      "Accuracy of SVM classifier on training set: 0.74\n",
      "Accuracy of SVM classifier on test set: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.44      0.27         9\n",
      "           2       0.33      0.16      0.21        19\n",
      "           3       0.33      0.20      0.25         5\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      1.00      1.00         6\n",
      "\n",
      "   micro avg       0.37      0.37      0.37        43\n",
      "   macro avg       0.42      0.47      0.42        43\n",
      "weighted avg       0.40      0.37      0.36        43\n",
      "\n",
      "F1Score:  36.0\n",
      "Accuracy:  37.0\n",
      "Precision :  40.0\n",
      "Recall:  37.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerajpadarthi/anaconda3/envs/work/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# load glass data set\n",
    "df = pd.read_csv('glass.csv')\n",
    "x = df[['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']]\n",
    "y = df['Type']\n",
    "\n",
    "# Use cross validation to create training and testing part\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Implement linear SVM method using scikit library\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'.format(svm.score(X_train, y_train)))\n",
    "# test data set acc\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'.format(svm.score(X_test, y_test)))\n",
    "\n",
    "svm = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test,svm))\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
    "print('F1Score: ',round(f1_score(y_test,svm, average='weighted')*100)) \n",
    "print('Accuracy: ',round(accuracy_score(y_test,svm)*100))\n",
    "print('Precision : ',round(precision_score(y_test,svm, average='weighted')*100))\n",
    "print('Recall: ',round(recall_score(y_test,svm, average='weighted')*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_test=df[[\"Sex\", \"Survived\"]].groupby(['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results: F= 372.4057236022147 , P = 1.406066130879677e-69\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "f_val, p_val = stats.f_oneway(grouped_test.get_group('female')['Survived'], grouped_test.get_group('male')['Survived'])  \n",
    "print( \"ANOVA results: F=\", f_val, \", P =\", p_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 9) (171,)\n",
      "(43, 9) (43,)\n",
      "Accuracy of Naive Bayes GaussianNB on training set: 0.59\n",
      "Accuracy of Naive Bayes GaussianNB on test set: 0.37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# load glass data set\n",
    "glass = pd.read_csv('glass.csv')\n",
    "x = glass[['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']]\n",
    "y = glass['Type']\n",
    "\n",
    "# Use cross validation to create training and testing part\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print('Accuracy of Naive Bayes GaussianNB on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "# Evaluate the model on testing part\n",
    "print('Accuracy of Naive Bayes GaussianNB on test set: {:.2f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-23aa85532f77>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-23aa85532f77>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    **Submitted by:**\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "**Submitted by:**\n",
    "\n",
    "Koushik Katakam – 11\n",
    "\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "_The goals of the ICP 3:_\n",
    "\n",
    "* Object oriented concepts\n",
    "* Web scraping\n",
    "* Numpy\n",
    "\n",
    "\n",
    "**Technologies Used:**\n",
    "\n",
    "* Pycharm\n",
    "\n",
    "**Program 1**\n",
    "\n",
    "_Programming Elements_\n",
    "\n",
    "_a. Create a data member to count the number of Employees_\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program1_Code_1.JPG)\n",
    "\n",
    "**the counter in the code above is to count the number the employees.**\n",
    "\n",
    "_b. Create a constructor to initialize name, family, salary, department_\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program1_Code_2.JPG)\n",
    "\n",
    "**I created the __init__ to initialize the name, family, salary and department.**\n",
    "\n",
    "_c. Create a function to average salary_\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program1_Code_3.JPG)\n",
    "\n",
    "**I used the salary_sum and counter to calculate the average salary for all the employees.**\n",
    "\n",
    "_d. Create a Fulltime Employee class and it should inherit the properties of Employee class_\n",
    "\n",
    "_e. Create the instances of Fulltime Employee class and Employee class and call their member functions._\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program1_Code_4.JPG)\n",
    "\n",
    "**Results:**\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program1_Output.JPG)\n",
    "\n",
    "\n",
    "**Program 2**\n",
    "\n",
    "_WEB SCRAPING_\n",
    "\n",
    "**Write a simple program that parse a Wiki page mentioned below and follow the instructions:**\n",
    "**[https://en.wikipedia.org/wiki/Deep_learning](https://en.wikipedia.org/wiki/Deep_learning)**\n",
    "\n",
    "_1.Parse the source code using the Beautiful Soup library and save the parsed code in a variable_\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program2_Code_1.JPG)\n",
    "\n",
    "**I used the source code to get the result page by searching Deep_learning and the first result in the page is**\n",
    "**the https://en.wikipedia.org/wiki/Deep_learning , and get the one result page and save in a variable, as the code below.**\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program2_Code_2.JPG)\n",
    "\n",
    "_2.Print out the title of the page_\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program2_Code_2.JPG)\n",
    "\n",
    "**I print the title of the result page in console and save the links of Deep Learning page in a file**\n",
    "\n",
    "_3. Find all the links in the page (‘a’ tag)_ \n",
    "\n",
    "_4. Iterate over each tag(above) then return the link using attribute \"href\" using get_\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program2_Code_3.JPG)\n",
    "\n",
    "**in the code above, I save all links and titles to files. [Check here for file links](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/tree/master/ICP3/Source)**\n",
    "\n",
    "**Results:**\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program2_Output.JPG)\n",
    "\n",
    "**Program 3**\n",
    "\n",
    "_NUMPY_\n",
    "\n",
    "_Using NumPy create random vector of size 15 having only Integers in the range 1-20. Write a program to replace the maximum value in the vector by 0._\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program3_Code.JPG)\n",
    "\n",
    "**I used the numpy where and amax to replace maximum value in the vector list by 0**\n",
    "\n",
    "**Results:**\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP3/Documentation/Program3_Output.JPG)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-239e46c0e668>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-239e46c0e668>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    **Submitted by:**\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "**Submitted by:**\n",
    "\n",
    "Koushik Katakam – 11\n",
    "\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "_The goals of the ICP 4:_\n",
    "\n",
    "* Classification algorithms. \n",
    "* Scikit learn. \n",
    "* Advanced concept related to machine learning algorithm like overfitting, underfitting, cross validation, evaluation for clustering methods\n",
    "\n",
    "\n",
    "**Technologies Used:**\n",
    "\n",
    "* Pycharm\n",
    "\n",
    "**Program 1**\n",
    "\n",
    "**1.Implementing Naïve Bayes method using scikit-learn libraryUse dataset available in [https://umkc.box.com/s/ea6wn1cidukan67t02j60nmp1ljln3kd](https://umkc.box.com/s/ea6wn1cidukan67t02j60nmp1ljln3kd)**\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program2_Code_1.JPG)\n",
    "\n",
    "_From the code, I used the link above to download the glass dataset and load the dataset in Python. Then, set x and y for preparing the training._\n",
    "\n",
    "**2.Use train_test_splitto create training and testing part**\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program2_Code_2.JPG)\n",
    "\n",
    "_I imported the train_test_split from sklearn.model_selection to do the splitting of data, and set test size is 0.2, which means that the training data size is 0.8 of all. I also print the data shape._\n",
    "\n",
    "**3.Evaluate the model on testing part**\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program2_Code_3.JPG)\n",
    "\n",
    "_Based on the question requirement, I used Naive bayes to train the glass data, and evaluate the model on testing dataset. The results are as below:_\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program2_Output.JPG)\n",
    "\n",
    "\n",
    "**Program 2**\n",
    "\n",
    "**1.Implementing Linear SVM method using scikit-learn library**\n",
    "\n",
    "**Use same dataset**\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program3_Code_1.JPG)\n",
    "\n",
    "_From the code, I used the link above to download the glass dataset and load the dataset in Python. Then, set x and y for preparing the training._\n",
    "\n",
    "**2.Use train_test_split to create training and testing part**\n",
    "\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program3_Code_2.JPG)\n",
    "\n",
    "_I imported the train_test_split from sklearn.model_selection to do the splitting of data, and set test size is 0.2, which means that the training data size is 0.8 of all. I also print the data shape._\n",
    "\n",
    "**3.Evaluate the model on testing part**\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program3_Code_3.JPG)\n",
    "\n",
    "_Based on the question requirement, I used Linear SVM to train the glass data, and evaluate the model on testing dataset. The results are as below:_\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program3_Output.JPG)\n",
    "\n",
    "So, compare the result with the Naive Bayes in the first question, the SVM got better accuracy.\n",
    "The reason is pretty simple and obvious. Because SVM is stronger for snippets than for longer documents.\n",
    "\n",
    "**Program 3**\n",
    "\n",
    "**1.Implementing RBF Kernel method using scikit-learn library**\n",
    "\n",
    "**Use same dataset**\n",
    "\n",
    "**2.Use train_test_split to create training and testing part**\n",
    "\n",
    "_All this process is done same as above._\n",
    "\n",
    "**3.Evaluate the model on testing part**\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program4_Code.JPG)\n",
    "\n",
    "_Based on the question requirement, I used RBF Kernel to train the glass data, and evaluate the model on testing dataset. The results are as below:_\n",
    "![](https://github.com/koushikkatakam1995/Python-DeepLearning_ICP/blob/master/ICP4/Documentation/Program4_Output.JPG)\n",
    "\n",
    "****How the result changed?****\n",
    "\n",
    "The accuracy of Linear SVM is 0.4 where as the accuracy of SVM using RBF Kernel SVM is 0.58 which increased as because the linear SVM generally separates the data in a linear manner where as the RBF kernel generally separates the data in higher dimensions and then seperates the data linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
